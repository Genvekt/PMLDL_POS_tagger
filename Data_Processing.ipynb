{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "unnecessary-passing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "lucky-venice",
   "metadata": {},
   "outputs": [],
   "source": [
    "ABSENT_PAIR = (\"UNKNOWN\", \"UNKNOWN\")\n",
    "RANDOM_CHANCE=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "composed-hebrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(file_path, with_tags=True):\n",
    "    \"\"\"\n",
    "    Read the dataset from file\n",
    "    Args:\n",
    "        file_path (str): path to the file to read from\n",
    "        with_tags (bool): flag that indicates the presence of tags in data.\n",
    "                          Use False to read test data.\n",
    "    Returns:\n",
    "        If with_tags is true, the list of tuples, one for each sentence\n",
    "            One tuple contains list of lowercase words and corresponding list of tags\n",
    "        Othervise the list of lowercase word lists, one fo each sentence\n",
    "    \"\"\"\n",
    "    \n",
    "    dataset = []\n",
    "    with open(file_path, \"r\") as data_file:\n",
    "        for line in data_file.readlines():\n",
    "            # Split each sentence into items\n",
    "            items = line[:-1].split(\" \")\n",
    "            if with_tags:\n",
    "                # If tags are present, create separate lists of words and tags\n",
    "                words = []\n",
    "                tags = []\n",
    "                for item in items:\n",
    "                    [word, tag] = item.rsplit(\"/\", 1)\n",
    "                    words.append(word.lower())\n",
    "                    tags.append(tag)\n",
    "                dataset.append((words, tags))\n",
    "            else:\n",
    "                # If tags are not present, append word list to the dataset\n",
    "                dataset.append([word.lower() for word in items])\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def dataset_to_dictionary(dataset, absent_pair=None):\n",
    "    word_to_idx = {}\n",
    "    idx_to_word = {}\n",
    "    tag_to_idx = {}\n",
    "    idx_to_tag = {}\n",
    "    for (words, tags) in dataset:\n",
    "        for word in words:\n",
    "            if word not in word_to_idx:\n",
    "                idx = len(word_to_idx)\n",
    "                word_to_idx[word] = idx\n",
    "                idx_to_word[idx] = word\n",
    "                \n",
    "        for tag in tags:\n",
    "            if tag not in tag_to_idx:\n",
    "                idx = len(tag_to_idx)\n",
    "                tag_to_idx[tag] = idx\n",
    "                idx_to_tag[idx] = tag\n",
    "                \n",
    "    if absent_pair is not None:\n",
    "        absent_word, absent_tag = absent_pair\n",
    "        if absent_word not in word_to_idx:\n",
    "            idx = len(word_to_idx)\n",
    "            word_to_idx[absent_word] = idx\n",
    "            idx_to_word[idx] = absent_word\n",
    "        if absent_tag not in tag_to_idx:\n",
    "            idx = len(tag_to_idx)\n",
    "            tag_to_idx[absent_tag] = idx\n",
    "            idx_to_tag[idx] = absent_tag\n",
    "    return word_to_idx, tag_to_idx, idx_to_word, idx_to_tag\n",
    "\n",
    "\n",
    "def prepare_sequence(sequence, dictionary, absent_key=None, random_key=None, random_chance=0.1):  \n",
    "    \"\"\"\n",
    "    Translate sequence according to dictionary.\n",
    "    Args:\n",
    "        sequence (list): list of keys\n",
    "        dictionary (dict): mapping from key to integer\n",
    "        absent_key (str): key which will substitute absent keys in sequence.\n",
    "                            if None, absent keys will be ignored\n",
    "        random_key (bool): key which will substitute keys in sequence \n",
    "                            with some chance (10% maybe)\n",
    "                            if None, random substitution will not be used.\n",
    "    Returns:\n",
    "        list of transformed sequence\n",
    "    \"\"\"\n",
    "    translated_seq = []\n",
    "    for key in sequence:\n",
    "        # Handle absent keys if absent_key specified\n",
    "        if key not in dictionary:\n",
    "            if absent_key is not None:\n",
    "                translated_seq.append(dictionary[absent_key])\n",
    "        # Random substitute if random_key specified\n",
    "        elif random_key is not None and torch.rand(1)[0]<random_chance:\n",
    "            translated_seq.append(dictionary[random_key])\n",
    "        else:\n",
    "            translated_seq.append(dictionary[key])\n",
    "    return translated_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "adjacent-permission",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = read_dataset(\"corpus.train\", with_tags=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "finite-latest",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx, tag_to_idx, idx_to_word, idx_to_tag = dataset_to_dictionary(train_dataset, absent_pair=ABSENT_PAIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "finite-trick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IN': 0,\n",
       " 'DT': 1,\n",
       " 'NNP': 2,\n",
       " 'CD': 3,\n",
       " 'NN': 4,\n",
       " '``': 5,\n",
       " \"''\": 6,\n",
       " 'POS': 7,\n",
       " '-LRB-': 8,\n",
       " 'VBN': 9,\n",
       " 'NNS': 10,\n",
       " 'VBP': 11,\n",
       " ',': 12,\n",
       " 'CC': 13,\n",
       " '-RRB-': 14,\n",
       " 'VBD': 15,\n",
       " 'RB': 16,\n",
       " 'TO': 17,\n",
       " '.': 18,\n",
       " 'VBZ': 19,\n",
       " 'NNPS': 20,\n",
       " 'PRP': 21,\n",
       " 'PRP$': 22,\n",
       " 'VB': 23,\n",
       " 'JJ': 24,\n",
       " 'MD': 25,\n",
       " 'VBG': 26,\n",
       " 'RBR': 27,\n",
       " ':': 28,\n",
       " 'WP': 29,\n",
       " 'WDT': 30,\n",
       " 'JJR': 31,\n",
       " 'PDT': 32,\n",
       " 'RBS': 33,\n",
       " 'WRB': 34,\n",
       " 'JJS': 35,\n",
       " '$': 36,\n",
       " 'RP': 37,\n",
       " 'FW': 38,\n",
       " 'EX': 39,\n",
       " 'SYM': 40,\n",
       " '#': 41,\n",
       " 'LS': 42,\n",
       " 'UH': 43,\n",
       " 'WP$': 44,\n",
       " '': 45,\n",
       " 'UNKNOWN': 46}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "anticipated-wagner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[38472, 305, 119, 578, 1936, 2510]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_sequence([\"innopolis\",\"is\",\"not\",\"very\",\"big\",\"town\"], word_to_idx, absent_key=ABSENT_PAIR[0], random_key=ABSENT_PAIR[0], random_chance=RANDOM_CHANCE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacterial-parish",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
