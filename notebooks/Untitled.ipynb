{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "funded-emerald",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.56.2-py2.py3-none-any.whl (72 kB)\n",
      "\u001b[K     |████████████████████████████████| 72 kB 589 kB/s eta 0:00:011\n",
      "\u001b[?25hInstalling collected packages: tqdm\n",
      "Successfully installed tqdm-4.56.2\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/home/genvekt/.pyenv/versions/3.7.9/envs/dl_tagger_env/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "incorrect-hawaiian",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "great-opportunity",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPECIAL_KEYS = {\n",
    "    \"absent\": {\n",
    "        \"word\": \"ABS\",\n",
    "        \"tag\": \"ABS\",\n",
    "        \"char\": \" \"\n",
    "    },\n",
    "    \"padding\": {\n",
    "        \"word\": \"PAD\",\n",
    "        \"tag\": \"PAD\",\n",
    "        \"char\": \" \"\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "WINDOW_LEN = 5\n",
    "BATCH_SIZE = 20\n",
    "RANDOM_WORD_SUB=0.01\n",
    "RANDOM_CHAR_SUB=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cloudy-character",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset(file_path, labeled=True):\n",
    "    \"\"\"\n",
    "    Read the dataset from file\n",
    "    Args:\n",
    "        file_path (str): path to the file to read from\n",
    "        with_tags (bool): flag that indicates the presence of tags in data.\n",
    "                          Use False to read test data.\n",
    "    Returns:\n",
    "        If with_tags is true, the list of tuples, one for each sentence\n",
    "            One tuple contains list of lowercase words and corresponding list of tags\n",
    "        Othervise the list of lowercase word lists, one fo each sentence\n",
    "    \"\"\"\n",
    "    \n",
    "    dataset = []\n",
    "    with open(file_path, \"r\") as data_file:\n",
    "        for line in data_file.readlines():\n",
    "            # Split each sentence into items\n",
    "            items = line[:-1].split(\" \")\n",
    "            if labeled:\n",
    "                # If tags are present, create separate lists of words and tags\n",
    "                words = []\n",
    "                tags = []\n",
    "                for item in items:\n",
    "                    [word, tag] = item.rsplit(\"/\", 1)\n",
    "                    words.append(word.lower())\n",
    "                    tags.append(tag)\n",
    "                dataset.append((words, tags))\n",
    "            else:\n",
    "                # If tags are not present, append word list to the dataset\n",
    "                dataset.append([word.lower() for word in items])\n",
    "    return dataset\n",
    "\n",
    "def add_key_to_dict(key, key_to_idx, idx_to_key):\n",
    "    if key not in key_to_idx:\n",
    "        idx = len(key_to_idx)\n",
    "        key_to_idx[key] = idx\n",
    "        idx_to_key[idx] = key\n",
    "\n",
    "def dataset_to_dictionary(dataset, scpecial_keys=None):\n",
    "    word_to_idx = {}\n",
    "    idx_to_word = {}\n",
    "    \n",
    "    tag_to_idx = {}\n",
    "    idx_to_tag = {}\n",
    "    \n",
    "    char_to_idx = {}\n",
    "    idx_to_char = {}\n",
    "    \n",
    "    for (words, tags) in dataset:\n",
    "        for word in words:\n",
    "            add_key_to_dict(word, word_to_idx, idx_to_word)\n",
    "            for letter in word:\n",
    "                add_key_to_dict(letter, char_to_idx, idx_to_char)\n",
    "            \n",
    "        for tag in tags:\n",
    "            add_key_to_dict(tag, tag_to_idx, idx_to_tag)\n",
    "                \n",
    "    if scpecial_keys is not None:\n",
    "        add_key_to_dict(scpecial_keys['absent']['word'], word_to_idx, idx_to_word)\n",
    "        add_key_to_dict(scpecial_keys['padding']['word'], word_to_idx, idx_to_word)\n",
    "        \n",
    "        add_key_to_dict(scpecial_keys['absent']['tag'], tag_to_idx, idx_to_tag)\n",
    "        add_key_to_dict(scpecial_keys['padding']['tag'], tag_to_idx, idx_to_tag)\n",
    "        for letter in scpecial_keys['absent']['word']:\n",
    "                add_key_to_dict(letter, char_to_idx, idx_to_char)\n",
    "        for letter in scpecial_keys['padding']['word']:\n",
    "                add_key_to_dict(letter, char_to_idx, idx_to_char)\n",
    "\n",
    "        add_key_to_dict(scpecial_keys['absent']['char'], char_to_idx, idx_to_char)\n",
    "        add_key_to_dict(scpecial_keys['padding']['char'], char_to_idx, idx_to_char)\n",
    "        \n",
    "    return word_to_idx, tag_to_idx, char_to_idx, idx_to_word, idx_to_tag, idx_to_char\n",
    "\n",
    "def pad_sequence(sequence, pad_key, required_len):\n",
    "    pad_len = required_len - len(sequence)\n",
    "    return sequence + [pad_key]*pad_len\n",
    "    \n",
    "def prepare_sequence(sequence, \n",
    "                     dictionary, \n",
    "                     absent_key=None, \n",
    "                     pad_key=None, \n",
    "                     required_len=50, \n",
    "                     random_chance=0):  \n",
    "    \"\"\"\n",
    "    Translate sequence according to dictionary.\n",
    "    Args:\n",
    "        sequence (list): list of keys\n",
    "        dictionary (dict): mapping from key to integer\n",
    "        absent_key (str): key which will substitute absent keys in sequence.\n",
    "                            if None, absent keys will be ignored\n",
    "        random_sub (bool): flag which indicatesthe need to randomly change keys in sequence \n",
    "                            with absent key with some chance (10% maybe)\n",
    "                            if None, random substitution will not be used.\n",
    "    Returns:\n",
    "        list of transformed sequence\n",
    "    \"\"\"\n",
    "    translated_seq = []\n",
    "    for key in sequence:\n",
    "        # Handle absent keys if absent_key specified\n",
    "        if key not in dictionary:\n",
    "            if absent_key is not None:\n",
    "                translated_seq.append(dictionary[absent_key])\n",
    "        # Random substitute if random_key specified\n",
    "        elif absent_key is not None and torch.rand(1)[0]<random_chance:\n",
    "            translated_seq.append(dictionary[absent_key])\n",
    "        else:\n",
    "            translated_seq.append(dictionary[key])\n",
    "    if pad_key is not None:\n",
    "        pad_len = required_len - len(translated_seq)\n",
    "        translated_seq += [dictionary[pad_key]]*pad_len\n",
    "    return torch.tensor(translated_seq, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "negative-suspension",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = read_dataset(\"../corpus.train\", labeled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "damaged-zimbabwe",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx, tag_to_idx, char_to_idx, idx_to_word, idx_to_tag, idx_to_char = dataset_to_dictionary(train_dataset, \n",
    "                                                                                                   scpecial_keys=SPECIAL_KEYS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "strategic-illinois",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class BatchedDataset:\n",
    "    def __init__(self, \n",
    "                 dataset, \n",
    "                 word_to_idx, \n",
    "                 char_to_idx, \n",
    "                 tag_to_idx, \n",
    "                 special_keys=None,\n",
    "                 batch_size = 10, \n",
    "                 labeled=True, \n",
    "                 sorting=True,\n",
    "                 random_word_sub=0.0,\n",
    "                 random_char_sub=0.0):\n",
    "        \n",
    "        self.labeled = labeled\n",
    "        self.word_to_idx = word_to_idx\n",
    "        self.char_to_idx = char_to_idx\n",
    "        self.tag_to_idx = tag_to_idx\n",
    "        self.special_keys = special_keys\n",
    "        self.random_word_sub = random_word_sub\n",
    "        self.random_char_sub = random_char_sub\n",
    "        if sorting:\n",
    "            # Sort sentens by their length\n",
    "            dataset = sorted(dataset, key=self.get_sort_func())\n",
    "        num_batches = math.ceil(len(dataset) / batch_size )\n",
    "        batches = []\n",
    "        for i in tqdm(range(num_batches)):\n",
    "            batch_items = dataset[i*batch_size:(i+1)*batch_size]\n",
    "            batch = self.create_batch(batch_items)\n",
    "            batches.append(batch)\n",
    "        self.batches = batches\n",
    "        self.word_to_idx = word_to_idx\n",
    "        self.char_to_idx = char_to_idx\n",
    "    \n",
    "    def default_spesial_keys(self):\n",
    "        return {\n",
    "            \"absent\": {\n",
    "                \"word\": \"ABS\",\n",
    "                \"tag\": \"ABS\",\n",
    "                \"char\": \" \"\n",
    "            },\n",
    "            \"padding\": {\n",
    "                \"word\": \"PAD\",\n",
    "                \"tag\": \"PAD\",\n",
    "                \"char\": \" \"\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def find_max_word_len(self, items):\n",
    "        max_word_len = 0\n",
    "        for item in items:\n",
    "            if self.labeled:\n",
    "                sent = item[0]\n",
    "            else:\n",
    "                sent = item\n",
    "            s_max_word_len= max([len(word) for word in sent])\n",
    "            max_word_len = s_max_word_len if s_max_word_len > max_word_len else max_word_len\n",
    "        return max_word_len\n",
    "    \n",
    "    def get_sort_func(self):\n",
    "        def sort_func(el):\n",
    "            if self.labeled:\n",
    "                return len(el[0])\n",
    "            else: \n",
    "                return len(el)\n",
    "        return sort_func\n",
    "    \n",
    "    def create_batch(self, items):\n",
    "        # max_s\n",
    "        if self.labeled:\n",
    "            max_sentence_len = max([len(item[0]) for item in items])\n",
    "        else:\n",
    "            max_sentence_len = max([len(item) for item in items])\n",
    "        # max_w\n",
    "        max_word_len = self.find_max_word_len(items)\n",
    "\n",
    "        batch_sentences = []\n",
    "        batch_mask = []\n",
    "        batch_taggs = []\n",
    "        batch_words = []\n",
    "\n",
    "        for item in items:\n",
    "            if self.labeled:\n",
    "                sent, taggs =  item\n",
    "                # [?,] -> [max_s,]\n",
    "                codded_taggs = prepare_sequence(taggs, \n",
    "                                            self.tag_to_idx, \n",
    "                                            absent_key=self.special_keys['absent']['tag'],\n",
    "                                            pad_key = self.special_keys['padding']['tag'],\n",
    "                                            required_len=max_sentence_len,\n",
    "                                            random_chance=0)\n",
    "                batch_taggs.append(codded_taggs)\n",
    "            else:\n",
    "                sent = item\n",
    "\n",
    "            # [?,] -> [max_s,]\n",
    "            padded_sentence = pad_sequence(sent,\n",
    "                                           pad_key=self.special_keys['padding']['word'],\n",
    "                                           required_len=max_sentence_len)\n",
    "            \n",
    "\n",
    "            codded_sentence = prepare_sequence(padded_sentence, \n",
    "                                            self.word_to_idx, \n",
    "                                            absent_key=self.special_keys['absent']['word'],\n",
    "                                            random_chance=self.random_word_sub)\n",
    "            \n",
    "            mask = (codded_sentence != self.word_to_idx[self.special_keys['padding']['word']]).type(torch.uint8)  \n",
    "\n",
    "\n",
    "            batch_sentences.append(codded_sentence)\n",
    "            batch_mask.append(mask)\n",
    "\n",
    "            codded_words = []\n",
    "            for word in padded_sentence:\n",
    "                # [?,] -> [max_w,]\n",
    "                codded_word = prepare_sequence(word, \n",
    "                                               self.char_to_idx, \n",
    "                                               absent_key=self.special_keys['absent']['char'],\n",
    "                                               pad_key = self.special_keys['padding']['char'],\n",
    "                                               required_len=max_word_len,\n",
    "                                               random_chance=self.random_char_sub)\n",
    "\n",
    "                codded_words.append(codded_word)\n",
    "            codded_words = torch.stack(codded_words,dim=0)\n",
    "            batch_words.append(codded_words)\n",
    "\n",
    "        # [B*max_s, max_w]\n",
    "        batch_words = torch.cat(batch_words, dim=0)\n",
    "\n",
    "        # [B,max_s]\n",
    "        batch_sentences = torch.stack(batch_sentences, dim=0)\n",
    "        batch_mask = torch.stack(batch_mask, dim=0)\n",
    "\n",
    "        if self.labeled:\n",
    "            # [B,max_s] (or [] if labeled id False)\n",
    "            batch_taggs = torch.stack(batch_taggs, dim=0)\n",
    "\n",
    "        return batch_sentences, batch_words, batch_taggs, batch_mask\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.batches)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.batches[idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "innocent-proceeding",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1897/1897 [01:46<00:00, 17.82it/s]\n"
     ]
    }
   ],
   "source": [
    "bds = BatchedDataset(train_dataset, word_to_idx, char_to_idx, tag_to_idx, special_keys=SPECIAL_KEYS, \n",
    "                    batch_size=BATCH_SIZE, labeled=True, sorting=True,\n",
    "                    random_word_sub=RANDOM_WORD_SUB,\n",
    "                    random_char_sub=RANDOM_CHAR_SUB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "pressed-retreat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[   40,    38,    41,    42,    39, 38473, 38473, 38473, 38473, 38473,\n",
       "          38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473,\n",
       "          38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473,\n",
       "          38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473,\n",
       "          38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473],\n",
       "         [   89,    98,    99,   100,   101,   102,   103,    39, 38473, 38473,\n",
       "          38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473,\n",
       "          38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473,\n",
       "          38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473,\n",
       "          38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473],\n",
       "         [    7,    91,    92,    93,    94,    95,    96,    97,    39, 38473,\n",
       "          38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473,\n",
       "          38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473,\n",
       "          38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473,\n",
       "          38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473],\n",
       "         [    7,    58,    59,    60,    61,    62,    63,    64,    45,     0,\n",
       "              7,    51, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473,\n",
       "          38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473,\n",
       "          38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473,\n",
       "          38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473],\n",
       "         [    6,   225,     7, 38472,   226,   119,   227,   228,     0,   158,\n",
       "            208,    39,     9, 38473, 38473, 38473, 38473, 38473, 38473, 38473,\n",
       "          38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473,\n",
       "          38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473,\n",
       "          38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473],\n",
       "         [   81,    82,    46,    83,    50,    84,    36,    85,    86,    87,\n",
       "             88,    86,    89,    90,    39, 38473, 38473, 38473, 38473, 38473,\n",
       "          38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38472,\n",
       "          38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473,\n",
       "          38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473],\n",
       "         [   81,    22,   104,     0,   105,   106,    22,   107,    68,   108,\n",
       "            109,    22,   110,    68,   111,   112,    39, 38473, 38473, 38473,\n",
       "          38473, 38473, 38472, 38473, 38473, 38473, 38473, 38473, 38473, 38473,\n",
       "          38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473,\n",
       "          38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473],\n",
       "         [    7,   157,   156,   172,   136,   173,   135,    36,   174,   175,\n",
       "              5,   176,   177,    68,   178,   179,    39, 38473, 38473, 38473,\n",
       "          38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473,\n",
       "          38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473,\n",
       "          38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473],\n",
       "         [  237,    55,   238,   239,     5,     7,   127,    22,   240,    36,\n",
       "            128,   241,    22,   242,   121,   243,   244,    39, 38473, 38473,\n",
       "          38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473,\n",
       "          38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473,\n",
       "          38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473],\n",
       "         [   43,    44,    45,    46,    47,    48,    49,    50,    51,    52,\n",
       "             36,    53,    54,    10,    55,    56,    45,     0,    57,    39,\n",
       "          38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473,\n",
       "          38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473,\n",
       "          38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473],\n",
       "         [  113,   114,   115,    36,     7,   116,    68,   117,   118,   119,\n",
       "             36,   120,   121,   122,    36,   123,    55,   124,   125,    68,\n",
       "             52,    30,   126,   127,    39, 38473, 38473, 38473, 38473, 38473,\n",
       "          38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473,\n",
       "          38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473],\n",
       "         [   65,    66,    22,    67,    68,    69,    70,    71,    22,    47,\n",
       "             72,    73,    74,    75,     7,    58,    59,    60,     0,    76,\n",
       "             68,    77,    22,    68,     0,    78,    79,    80,    39, 38473,\n",
       "          38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473,\n",
       "          38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473],\n",
       "         [  229,    22,     7,   230,   231,   135,    22,   232,    68,   163,\n",
       "            126,   127,    36,   174,   125,    68,    52,     5,   121,   169,\n",
       "            170,   171,   233,    55,    89,   234,   235,     7,   236,    39,\n",
       "          38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473,\n",
       "          38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473],\n",
       "         [   89,   128,   129,    36,   130,   131,   132,    75,   133,   134,\n",
       "            135,   136,   137,     7,   138,     5,   123,   139,   140,   141,\n",
       "            142,    89,   143,   144,    22,   145,   113,    68,   146,   147,\n",
       "            148,   149,    39, 38473, 38473, 38473, 38473, 38473, 38473, 38473,\n",
       "          38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473],\n",
       "         [  113,    22,   147,   148,    68,   126,   262,   263,   264,   265,\n",
       "             36,   266,   139,     7,   267,    22,    68,     7,   268,   100,\n",
       "            269,   270,   271,   272,   273,   194,   163,   268,     0,   274,\n",
       "             22,   275,   255,    47,    39, 38473, 38473, 38473, 38473, 38473,\n",
       "          38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473, 38473],\n",
       "         [  150,   151,     7,   152,     0,   153,    36,     7,   154,    55,\n",
       "            155,   156,   157,   158,   159,   160,   161,    22,   162,   163,\n",
       "            164,    22,   136,   165,   166,   167,   135,    87,   131,   141,\n",
       "              0,   121,   168,   169,   170,   171,    39, 38473, 38473, 38473,\n",
       "          38473, 38473, 38472, 38473, 38473, 38473, 38473, 38473, 38473],\n",
       "         [    6,     7,   128,   100,   205,   206,   207,    36,     7,   208,\n",
       "              5,    89,   209,   210,   211,    22,     9,   212,   213,   214,\n",
       "            215,     5,   216,    22,   217,    22,     0,   218,     5,     7,\n",
       "            219,   153,     7,   154,   100,   220,   221,     7,   156,   222,\n",
       "            157,   223,   224,    39, 38473, 38473, 38473, 38473, 38473],\n",
       "         [    7,   156,   222,   157,     0,     1,   245,    36,   246, 38472,\n",
       "            248,    68,   249,   250,    30,     7,   135,     6,   251,   114,\n",
       "            227,   252,     7,   253,    22,     9,    47,   254,   255,    22,\n",
       "            256,   257,    10,     7,   128,    12,   258,     5,   259,   260,\n",
       "             22,   261,   157,     7,   156,    39, 38473, 38473, 38473],\n",
       "         [  166,     5,     7,   153,   180,   161,   181,   182,   100,   102,\n",
       "            183,   184,    30,     7,   185,   124,   186,   187,   188,    68,\n",
       "              7,    80,   189,   183,   190,   191,     7,   192,   193,   188,\n",
       "            161,   194,   195,     0,   123,   139,   196,   197,   198,   199,\n",
       "            200,    36,   201,   202,     5,   203,   204,    39, 38473],\n",
       "         [    0,     1,     2,     3,     4,     5,     6,     7,     8,     9,\n",
       "             10,    11,    12,    13,    14,    15,     6,    16,    17,    18,\n",
       "              7,    19,     0,    20,    21,    22,     9,    23,    24,    25,\n",
       "             26,    22,     7,    27,     5,    28,    22,    29,    30,    31,\n",
       "             32,    22,    33,    34,    35,    36,    37,    38,    39]]),\n",
       " tensor([[16, 17,  6,  ..., 63, 63, 63],\n",
       "         [15,  2,  2,  ..., 63, 63, 63],\n",
       "         [18, 23,  2,  ..., 63, 63, 63],\n",
       "         ...,\n",
       "         [ 4, 15,  9,  ..., 63, 63, 63],\n",
       "         [15,  2,  2,  ..., 63, 63, 63],\n",
       "         [ 6, 63, 63,  ..., 63, 63, 63]]),\n",
       " tensor([[ 2,  2, 19,  2, 18, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47,\n",
       "          47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47,\n",
       "          47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47],\n",
       "         [ 1,  4,  4, 19, 16,  9,  9, 18, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47,\n",
       "          47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47,\n",
       "          47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47],\n",
       "         [ 1, 24,  4, 25, 23, 24,  2,  3, 18, 47, 47, 47, 47, 47, 47, 47, 47, 47,\n",
       "          47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47,\n",
       "          47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47],\n",
       "         [ 1,  4,  4,  4, 24,  4, 15,  3, 10,  0,  1,  2, 47, 47, 47, 47, 47, 47,\n",
       "          47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47,\n",
       "          47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47],\n",
       "         [ 5, 16,  1,  4, 15, 16, 16, 23,  0,  1,  4, 18,  6, 47, 47, 47, 47, 47,\n",
       "          47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47,\n",
       "          47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47],\n",
       "         [ 2,  2,  2, 15, 22,  4, 17,  3, 10,  0,  3, 10,  1,  4, 18, 47, 47, 47,\n",
       "          47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47,\n",
       "          47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47],\n",
       "         [ 2, 12,  9,  0,  2,  2, 12, 19, 13, 19, 24, 12,  4, 13,  4, 10, 18, 47,\n",
       "          47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47,\n",
       "          47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47],\n",
       "         [ 1,  9, 10, 16, 25, 23, 10, 17, 23, 10,  0, 10, 27, 13, 27, 16, 18, 47,\n",
       "          47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47,\n",
       "          47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47],\n",
       "         [13,  0,  3,  4,  0,  1, 10, 12, 26, 17,  2, 10, 12, 11, 22, 10, 16, 18,\n",
       "          47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47,\n",
       "          47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47],\n",
       "         [ 2,  2, 20,  2, 15, 21, 19, 22,  2, 10, 17, 23, 24,  0,  0,  3, 10,  0,\n",
       "           3, 18, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47,\n",
       "          47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47],\n",
       "         [10, 11, 26, 17,  1, 20, 13,  2,  2, 16, 17, 23, 22,  4, 17,  4,  0,  4,\n",
       "          10, 13, 10,  0, 24, 10, 18, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47,\n",
       "          47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47],\n",
       "         [ 2,  2, 12,  4, 13, 24,  4,  4, 12, 15, 21, 19,  4,  0,  1,  4,  4,  4,\n",
       "           0,  2, 13,  2, 12, 13,  0, 24, 24, 10, 18, 47, 47, 47, 47, 47, 47, 47,\n",
       "          47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47],\n",
       "         [16, 12,  1, 10, 11, 10, 12, 10, 13, 24, 24, 10, 17, 23, 10, 13, 10,  0,\n",
       "          22, 10,  7, 10,  0,  0,  1,  4,  0,  1,  4, 18, 47, 47, 47, 47, 47, 47,\n",
       "          47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47],\n",
       "         [ 1,  2,  4, 17, 23,  4, 10,  0,  1,  4, 10, 25, 23,  1,  4,  0,  4,  0,\n",
       "           4, 10,  0,  1, 24,  4, 12, 24, 10, 13, 24,  4, 10, 11, 18, 47, 47, 47,\n",
       "          47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47],\n",
       "         [10, 12,  4, 10, 13, 24, 10, 15,  0,  4, 17, 23,  0,  1, 10, 12, 13,  1,\n",
       "           4, 19,  9, 31,  4,  0, 16,  1, 24,  4,  0,  4, 12,  2,  2, 15, 18, 47,\n",
       "          47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47],\n",
       "         [21, 11,  1,  4,  0, 10, 17,  1,  4,  0,  4, 10, 15,  1, 24,  4,  0, 12,\n",
       "           0, 24, 10, 12, 25, 23, 24, 24, 10,  0, 26, 10,  0, 22, 24, 10,  7, 10,\n",
       "          18, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47],\n",
       "         [ 5,  1,  2, 19, 16,  9,  4, 17,  1,  4,  0,  1, 24,  4,  4, 12,  6, 15,\n",
       "           2,  2,  2,  0,  2, 12,  2, 12,  0,  3,  0,  1,  3, 10,  1,  4, 19,  9,\n",
       "           0,  1, 10, 15,  9,  2,  3, 18, 47, 47, 47, 47, 47],\n",
       "         [ 1, 10, 15,  9,  0,  1,  4, 17, 23, 24,  4, 13, 23,  4,  0,  1, 10,  5,\n",
       "          29, 11, 16, 26,  1, 10, 12,  6, 15,  2,  2, 12, 24,  4,  0,  1,  2,  7,\n",
       "           4,  0,  4,  4, 12, 30, 15,  1, 10, 18, 47, 47, 47],\n",
       "         [24,  0,  1, 10, 11,  0,  4,  4, 19,  9, 16,  9,  0,  1,  3,  4,  4,  4,\n",
       "          28, 13,  1, 10, 16, 16,  9,  0,  1, 24,  4, 28,  0,  1,  4,  0,  4,  0,\n",
       "           4, 10, 25, 23, 10, 17, 23, 16,  0, 10, 16, 18, 47],\n",
       "         [ 0,  1,  2,  3,  4,  0,  5,  1,  4,  6,  0,  2,  7,  2,  2,  8,  5,  9,\n",
       "          10, 11,  1,  4,  0,  2,  2, 12,  6,  4, 13, 10, 14, 12,  1,  4,  0,  2,\n",
       "          12,  9,  0,  2,  2, 12, 15, 16,  9, 17,  2,  2, 18]]),\n",
       " tensor([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "          0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "          0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,\n",
       "          0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "          0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1]], dtype=torch.uint8))"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "usual-dodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FinalModel(nn.Module):\n",
    "    def __init__(self, char_emb_dim, word_emb_dim, hidden_dim, vocab_size, charset_size, tagset_size, window, l):\n",
    "        super(FinalModel, self).__init__()\n",
    "        self.char_embeddings = nn.Embedding(charset_size, char_emb_dim)\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, word_emb_dim)\n",
    "        self.conv1 = nn.Conv1d(char_emb_dim, l, window, padding=(window-1)//2)\n",
    "        self.lstm = nn.LSTM(word_emb_dim+l, hidden_dim, bidirectional=True)\n",
    "        self.hidden2tag = nn.Linear(hidden_dim*2, tagset_size)\n",
    "\n",
    "    def forward(self, batch_sentence, batch_words):\n",
    "        # Pass each window through CNN, max_pool the results for each word\n",
    "        \n",
    "        B, S = batch_sentence.shape\n",
    "        \n",
    "        # [B*S, W, c_emb]\n",
    "        chars_batch = self.char_embeddings(batch_words)\n",
    "        \n",
    "        # [B*S, c_emb, W]\n",
    "        chars_batch = chars_batch.permute(0,2,1)\n",
    "        \n",
    "        # [B*S, l, W]\n",
    "        conv_out = self.conv1(chars_batch)\n",
    "        \n",
    "        # [B*S, l]\n",
    "        pool_out, _ = torch.max(conv_out, dim=2)\n",
    "        \n",
    "        # [B, S, l]\n",
    "        cnn_word_vecs = pool_out.reshape((B, S, -1))\n",
    "        \n",
    "        # [B, S, w_emb]\n",
    "        word_embeds = self.word_embeddings(batch_sentence)\n",
    "        \n",
    "        # [B, S, w_emb+l]\n",
    "        concated = torch.cat((word_embeds, cnn_word_vecs), dim=2)\n",
    "        \n",
    "        # [B, S, hidden]\n",
    "        lstm_out, _ = self.lstm(concated)\n",
    "        \n",
    "        # [B, S, T]\n",
    "        tag_space = self.hidden2tag(lstm_out)\n",
    "        tag_scores = F.log_softmax(tag_space, dim=2)\n",
    "        return tag_scores    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "minus-project",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FinalModel(char_emb_dim=10, \n",
    "                   word_emb_dim=100, \n",
    "                   hidden_dim=16, \n",
    "                   vocab_size=len(word_to_idx), \n",
    "                   charset_size=len(char_to_idx),\n",
    "                   tagset_size=len(tag_to_idx),\n",
    "                   window=WINDOW_LEN,\n",
    "                   l=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "surface-semiconductor",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "japanese-respect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t loss = 3.806893825531006\n",
      "\t loss = 0.5268096327781677\n",
      "\t loss = 0.2668271064758301\n",
      "\t loss = 0.20654650032520294\n",
      "Epoch 0: loss=0.22369877994060516\n",
      "Val accuracy: 0.9146148682301479\n",
      "\t loss = 0.4512713849544525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/genvekt/.pyenv/versions/3.7.9/envs/dl_tagger_env/lib/python3.7/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type FinalModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t loss = 0.3112446665763855\n",
      "\t loss = 0.1868566870689392\n",
      "\t loss = 0.17567184567451477\n",
      "Epoch 1: loss=0.1816858947277069\n",
      "Val accuracy: 0.9165204963295004\n",
      "\t loss = 0.2689725458621979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/genvekt/.pyenv/versions/3.7.9/envs/dl_tagger_env/lib/python3.7/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type FinalModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t loss = 0.2768263816833496\n",
      "\t loss = 0.1725994497537613\n",
      "\t loss = 0.15808017551898956\n",
      "Epoch 2: loss=0.16721951961517334\n",
      "Val accuracy: 0.9164555317352043\n",
      "\t loss = 0.22781860828399658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/genvekt/.pyenv/versions/3.7.9/envs/dl_tagger_env/lib/python3.7/site-packages/torch/serialization.py:360: UserWarning: Couldn't retrieve source code for container of type FinalModel. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-188-943913b1791a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtaggs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.9/envs/dl_tagger_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m                 \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshare_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "losses = []\n",
    "\n",
    "for epoch in range(10):\n",
    "    for step in range(len(bds)):\n",
    "        model.zero_grad()\n",
    "\n",
    "        sentences, words, taggs, mask = bds[step]\n",
    "\n",
    "        tag_scores = model(sentences, words)\n",
    "        B, S, T = tag_scores.shape\n",
    "        # tag_scores = torch.argmax(tag_scores, dim=1) #.reshape(-1)\n",
    "        mask = mask.reshape(-1)\n",
    "        tag_scores= tag_scores.reshape((B*S,T))\n",
    "        tag_scores = tag_scores * mask.unsqueeze(1)\n",
    "        taggs = taggs.reshape(-1) * mask\n",
    "\n",
    "        loss = loss_function(tag_scores, taggs)\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if step % 500 == 0:\n",
    "            print(f\"\\t loss = {losses[-1]}\")\n",
    "    print(f\"Epoch {epoch}: loss={losses[-1]}\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        for step in range(len(batchizer_test)):\n",
    "            sentences, words, taggs, mask = batchizer_test[step]\n",
    "            tag_scores = model(sentences, words)\n",
    "            # tag_scores = torch.argmax(tag_scores, dim=1) #.reshape(-1)\n",
    "            mask = mask.reshape(-1)\n",
    "            taggs = taggs.reshape(-1) * mask\n",
    "            tag_scores= tag_scores.reshape((-1,tag_scores.shape[-1]))\n",
    "            pred = torch.argmax(tag_scores, dim=1)*mask\n",
    "            # print(taggs.shape, pred.shape)\n",
    "            y_true += taggs.tolist()\n",
    "            y_pred += pred.tolist()\n",
    "        print(\"Val accuracy:\",accuracy_score(y_true, y_pred))\n",
    "        \n",
    "    torch.save(model, 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "polished-bridge",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95/95 [00:05<00:00, 18.57it/s]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = read_dataset(\"../corpus.answer\", labeled=True)\n",
    "batchizer_test = BatchedDataset(test_dataset, word_to_idx, char_to_idx, tag_to_idx, \n",
    "                                batch_size=BATCH_SIZE, special_keys=SPECIAL_KEYS,labeled=True,sorting=True,\n",
    "                                random_word_sub=0.0, random_char_sub=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "lovely-authority",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FinalModel(\n",
       "  (char_embeddings): Embedding(64, 30)\n",
       "  (word_embeddings): Embedding(38474, 50)\n",
       "  (conv1): Conv1d(30, 20, kernel_size=(5,), stride=(1,), padding=(2,))\n",
       "  (lstm): LSTM(70, 40, bidirectional=True)\n",
       "  (hidden2tag): Linear(in_features=80, out_features=48, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "functional-coverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "y_pred = []\n",
    "for step in range(len(batchizer_test)):\n",
    "    sentences, words, taggs = batchizer_test[step]\n",
    "    tag_scores = model(sentences, words)\n",
    "    # tag_scores = torch.argmax(tag_scores, dim=1) #.reshape(-1)\n",
    "    taggs = taggs.reshape(-1)\n",
    "    tag_scores= tag_scores.reshape((-1,tag_scores.shape[-1]))\n",
    "    pred = torch.argmax(tag_scores, dim=1)\n",
    "    # print(taggs.shape, pred.shape)\n",
    "    y_true += taggs.tolist()\n",
    "    y_pred += pred.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "committed-filling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8347018765464538\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "precise-capitol",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "united-catholic",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(range(len(losses))), losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "decimal-hygiene",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(list(range(len(losses))), losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "alpha-coverage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.tar.gz (1.1 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-0.24.1-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 22.3 MB 4.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-2.1.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/genvekt/.pyenv/versions/3.7.9/envs/dl_tagger_env/lib/python3.7/site-packages (from scikit-learn->sklearn) (1.20.0)\n",
      "Collecting joblib>=0.11\n",
      "  Downloading joblib-1.0.1-py3-none-any.whl (303 kB)\n",
      "\u001b[K     |████████████████████████████████| 303 kB 3.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scipy>=0.19.1\n",
      "  Downloading scipy-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (27.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 27.4 MB 6.2 MB/s eta 0:00:01\n",
      "\u001b[?25hUsing legacy setup.py install for sklearn, since package 'wheel' is not installed.\n",
      "Installing collected packages: threadpoolctl, joblib, scipy, scikit-learn, sklearn\n",
      "    Running setup.py install for sklearn ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed joblib-1.0.1 scikit-learn-0.24.1 scipy-1.6.0 sklearn-0.0 threadpoolctl-2.1.0\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/home/genvekt/.pyenv/versions/3.7.9/envs/dl_tagger_env/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "capable-stack",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.3.4-cp37-cp37m-manylinux1_x86_64.whl (11.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.5 MB 2.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pillow>=6.2.0\n",
      "  Downloading Pillow-8.1.0-cp37-cp37m-manylinux1_x86_64.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 2.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.1-cp37-cp37m-manylinux1_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 3.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.15 in /home/genvekt/.pyenv/versions/3.7.9/envs/dl_tagger_env/lib/python3.7/site-packages (from matplotlib) (1.20.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/genvekt/.pyenv/versions/3.7.9/envs/dl_tagger_env/lib/python3.7/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/genvekt/.pyenv/versions/3.7.9/envs/dl_tagger_env/lib/python3.7/site-packages (from matplotlib) (2.4.7)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/genvekt/.pyenv/versions/3.7.9/envs/dl_tagger_env/lib/python3.7/site-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
      "Installing collected packages: pillow, kiwisolver, cycler, matplotlib\n",
      "Successfully installed cycler-0.10.0 kiwisolver-1.3.1 matplotlib-3.3.4 pillow-8.1.0\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 21.0.1 is available.\n",
      "You should consider upgrading via the '/home/genvekt/.pyenv/versions/3.7.9/envs/dl_tagger_env/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conceptual-incentive",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
